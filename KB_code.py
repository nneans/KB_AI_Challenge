# =========================================================
# KB AI Challenge - Professional RAG System (Multilingual)
# =========================================================

import os
import sys
import numpy as np
import traceback
import fitz  # PyMuPDF
from typing import List

# --- ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„í¬íŠ¸ ---
import gradio as gr
import speech_recognition as sr
from dotenv import load_dotenv

# .env ë¡œë“œ
load_dotenv()

from deep_translator import GoogleTranslator
from sentence_transformers import SentenceTransformer
from groq import Groq
from qdrant_client import QdrantClient
from qdrant_client.models import Distance, VectorParams, PointStruct

try:
    from langchain.text_splitter import RecursiveCharacterTextSplitter
except ImportError:
    from langchain_text_splitters import RecursiveCharacterTextSplitter

# =========================================================
# 1. ì„¤ì • ë° ì´ˆê¸°í™”
# =========================================================

GROQ_API_KEY = os.environ.get("GROQ_API_KEY", "your_groq_api_key_here")
EMBEDDING_MODEL_NAME = "jhgan/ko-sroberta-multitask"
GROQ_MODEL_NAME = "llama-3.3-70b-versatile"
COLLECTION_NAME = "local_kb"

print("ğŸ› ï¸ ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì¤‘... (System Init)")

# ëª¨ë¸ ë¡œë“œ
embedding_model = SentenceTransformer(EMBEDDING_MODEL_NAME)
embedding_model.max_seq_length = 512

# Qdrant (ë©”ëª¨ë¦¬)
qdrant_client = QdrantClient(":memory:")
try:
    qdrant_client.recreate_collection(
        collection_name=COLLECTION_NAME,
        vectors_config=VectorParams(size=768, distance=Distance.COSINE),
    )
    print(f"âœ… Qdrant Collection Ready.")
except Exception as e:
    print(f"âŒ Qdrant Error: {e}")

# Groq Init
groq_client = None
if GROQ_API_KEY and GROQ_API_KEY != "your_groq_api_key_here":
    try:
        groq_client = Groq(api_key=GROQ_API_KEY)
    except Exception as e:
        print(f"âŒ Groq Error: {e}")
else:
    print("âš ï¸ Groq API Key Missing.")

doc_id_counter = 0

print("âœ… System Ready.")


# =========================================================
# 2. ë‹¤êµ­ì–´ ì§€ì› ë¡œì§ (Translation & STT)
# =========================================================

LANG_MAP = {
    "í•œêµ­ì–´ (Korean)": {"code": "ko", "stt": "ko-KR"},
    "English (ì˜ì–´)": {"code": "en", "stt": "en-US"},
    "æ—¥æœ¬èª (Japanese)": {"code": "ja", "stt": "ja-JP"},
    "ä¸­æ–‡ (Chinese)": {"code": "zh-CN", "stt": "zh-CN"}
}

def translate_text(text, target_lang_code):
    try:
        if target_lang_code == "ko": return text
        return GoogleTranslator(source='auto', target=target_lang_code).translate(text)
    except:
        return text

def translate_to_korean(text):
    try:
        return GoogleTranslator(source='auto', target='ko').translate(text)
    except:
        return text

# =========================================================
# 3. í•µì‹¬ ë¡œì§ (RAG Pipeline)
# =========================================================

def process_uploaded_files(files):
    """PDF ì²˜ë¦¬ ë° ì„ë² ë”©"""
    global doc_id_counter
    if not files: return "íŒŒì¼ì´ ì„ íƒë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."
    
    total_chunks = 0
    status_msg = ""
    text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=50, length_function=len)

    for file in files:
        try:
            file_path = file.name if hasattr(file, 'name') else file
            doc = fitz.open(file_path)
            file_text = ""
            for page in doc: file_text += page.get_text()
            
            if not file_text.strip():
                status_msg += f"âš ï¸ {os.path.basename(file_path)}: í…ìŠ¤íŠ¸ ì—†ìŒ.\n"
                continue
                
            chunks = text_splitter.split_text(file_text)
            points = []
            for i, chunk in enumerate(chunks):
                vector = embedding_model.encode(chunk).tolist()
                payload = {"filename": os.path.basename(file_path), "text": chunk}
                points.append(PointStruct(id=doc_id_counter, vector=vector, payload=payload))
                doc_id_counter += 1
            
            if points:
                qdrant_client.upsert(collection_name=COLLECTION_NAME, points=points)
                total_chunks += len(points)
                status_msg += f"âœ… {os.path.basename(file_path)} ({len(points)} ê°œ ì €ì¥ë¨)\n"
            
        except Exception as e:
            status_msg += f"âŒ ì˜¤ë¥˜: {os.path.basename(file_path)} - {str(e)}\n"
            
    return f"ì´ {total_chunks}ê°œ ë°ì´í„° ì²˜ë¦¬ ì™„ë£Œ.\n\n{status_msg}"

def search_knowledge_base(query, top_k=5):
    try:
        query_vector = embedding_model.encode(query).tolist()
        res = qdrant_client.query_points(
            collection_name=COLLECTION_NAME, query=query_vector, limit=top_k, with_payload=True
        )
        return res.points
    except:
        return []

def generate_answer_groq(query, context_text):
    if not groq_client: return "API í‚¤ê°€ í•„ìš”í•©ë‹ˆë‹¤."
    
    system_prompt = """
    ë‹¹ì‹ ì€ KB ê¸ˆìœµê·¸ë£¹ì˜ ì „ë¬¸ AI ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤.
    ì œê³µëœ [ë¬¸ë§¥]ì— ê¸°ë°˜í•˜ì—¬ ì§ˆë¬¸ì— ëŒ€í•´ ì •í™•í•˜ê³  ì „ë¬¸ì ì¸ ë‹µë³€ì„ ì‘ì„±í•˜ì„¸ìš”.
    ëª¨ë¥´ëŠ” ë‚´ìš©ì€ ëª¨ë¥¸ë‹¤ê³  ë‹µí•˜ê³ , ì¶”ì¸¡í•˜ì§€ ë§ˆì„¸ìš”.
    ë‹µë³€ì€ í•œêµ­ì–´ë¡œ ì‘ì„±í•˜ì„¸ìš”.
    """
    user_prompt = f"ì§ˆë¬¸: {query}\n\n[ë¬¸ë§¥]\n{context_text}"
    try:
        response = groq_client.chat.completions.create(
            messages=[{"role": "system", "content": system_prompt}, {"role": "user", "content": user_prompt}],
            model=GROQ_MODEL_NAME, temperature=0.1
        )
        return response.choices[0].message.content
    except Exception as e:
        return f"ì‘ë‹µ ìƒì„± ì˜¤ë¥˜: {e}"

def run_rag_chat(message, history, lang_selection):
    if not message: return "", history, ""
    
    target_lang = LANG_MAP[lang_selection]["code"]
    
    # 1. ì…ë ¥ ë²ˆì—­ (Target -> Korean)
    korean_query = message
    if target_lang != "ko":
        korean_query = translate_to_korean(message)
    
    # 2. ê²€ìƒ‰ & ë‹µë³€ ìƒì„± (Korean)
    hits = search_knowledge_base(korean_query)
    if not hits:
        bot_response_ko = "ì£„ì†¡í•©ë‹ˆë‹¤. ê´€ë ¨ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
        reference_text = "ì°¸ê³  ë¬¸ì„œ ì—†ìŒ"
    else:
        context_text = "\n\n".join([h.payload['text'] for h in hits])
        # ì¤‘ë³µ ì œê±° ë° ê·¸ë£¹í™” (File grouping)
        ref_data = {}
        for h in hits:
            fname = h.payload['filename']
            if fname not in ref_data:
                ref_data[fname] = []
            ref_data[fname].append(h.score)
            
        refs = []
        for fname, scores in ref_data.items():
            refs.append(f"- {fname} (ê´€ë ¨ ë‚´ìš© {len(scores)}ê±´, ìµœê³  ìœ ì‚¬ë„: {max(scores):.2f})")
        reference_text = "\n".join(refs)
        bot_response_ko = generate_answer_groq(korean_query, context_text)
    
    # 3. ë‹µë³€ ë²ˆì—­ (Korean -> Target)
    final_response = bot_response_ko
    if target_lang != "ko":
        translated_response = translate_text(bot_response_ko, target_lang)
        final_response = f"{translated_response}\n\n---\n[í•œêµ­ì–´ ì›ë¬¸]\n{bot_response_ko}"
    
    # íˆìŠ¤í† ë¦¬ì— ì¶”ê°€ (Messages Format for Gradio 6.x)
    new_history = history + [
        {"role": "user", "content": message},
        {"role": "assistant", "content": final_response}
    ]
    return "", new_history, reference_text

def voice_to_text_chat(audio, history, lang_selection):
    if audio is None: return "", history, "ìŒì„± ì…ë ¥ ì—†ìŒ"
    
    stt_lang = LANG_MAP[lang_selection]["stt"]
    
    try:
        sample_rate, audio_numpy = audio
        if audio_numpy.dtype == np.float32:
            audio_numpy = (audio_numpy * 32767).astype(np.int16)
        if len(audio_numpy.shape) > 1:
            audio_numpy = audio_numpy.mean(axis=1).astype(np.int16)
        audio_data = sr.AudioData(audio_numpy.tobytes(), sample_rate, 2)
        r = sr.Recognizer()
        
        # ì„ íƒëœ ì–¸ì–´ë¡œ ì¸ì‹
        text = r.recognize_google(audio_data, language=stt_lang)
        
        # ì±„íŒ… í•¨ìˆ˜ í˜¸ì¶œ
        return run_rag_chat(text, history, lang_selection)
        
    except sr.UnknownValueError:
        return "", history, "ìŒì„±ì„ ì´í•´í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
    except Exception as e: 
        return "", history, f"ì˜¤ë¥˜: {e}"

# =========================================================
# 4. UI Layout (Clean Professional Korean)
# =========================================================

theme = gr.themes.Soft(
    primary_hue="amber",
    neutral_hue="slate",
    font=[gr.themes.GoogleFont("Noto Sans KR"), "sans-serif"]
)

css = """
footer {visibility: hidden !important;}
.gradio-container {min-height: 0px !important;}
"""

with gr.Blocks(theme=theme, title="KB AI Challenge", css=css) as demo:
    
    with gr.Row():
        # --- LEFT SIDEBAR ---
        with gr.Column(scale=1, min_width=300, variant="panel"):
            gr.Markdown("## KB AI Challenge")
            gr.Markdown("**ë‹¤êµ­ì–´ ê¸ˆìœµ AI ì–´ì‹œìŠ¤í„´íŠ¸**")
            
            with gr.Group():
                lang_dropdown = gr.Dropdown(
                    choices=list(LANG_MAP.keys()), 
                    value="í•œêµ­ì–´ (Korean)", 
                    label="ì–¸ì–´ ì„¤ì •",
                    interactive=True
                )
                
                file_input = gr.File(label="ì§€ì‹ ë² ì´ìŠ¤ (PDF)", file_count="multiple", file_types=[".pdf"])
                with gr.Row():
                    upload_btn = gr.Button("ì—…ë¡œë“œ ë° ë¶„ì„", variant="primary", size="sm")
                    upload_status = gr.Textbox(show_label=False, placeholder="ìƒíƒœ ëŒ€ê¸° ì¤‘...", interactive=False, lines=1, max_lines=1)
            
            gr.Markdown("### ìŒì„± ëŒ€í™”")
            audio_input = gr.Audio(sources=["microphone"], type="numpy", label="ìŒì„± ì…ë ¥", show_label=False)
            
            with gr.Accordion("ì‹œìŠ¤í…œ ì•„í‚¤í…ì²˜", open=False):
                gr.Markdown(
                    """
                    **ìµœì í™” ë‚´ì—­**
                    1. **STT**: Google Speech API
                    2. **ë²ˆì—­**: Google Translate API
                    3. **LLM**: Groq LPU (Llama 3)
                    """
                )

        # --- RIGHT MAIN ---
        with gr.Column(scale=3):
            # chatbot (Messages format)
            chatbot = gr.Chatbot(label="ëŒ€í™”", height=500, show_label=False)
            
            # References
            gr.Markdown("**ì°¸ê³  ë¬¸ì„œ**")
            ref_output = gr.Textbox(show_label=False, interactive=False, lines=3, max_lines=5, placeholder="ê´€ë ¨ ë¬¸ì„œê°€ í‘œì‹œë©ë‹ˆë‹¤.")
            
            # Input Area
            with gr.Row():
                msg = gr.Textbox(
                    scale=6, 
                    show_label=False, 
                    placeholder="ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”...",
                    container=False
                )
                submit_btn = gr.Button("ì „ì†¡", scale=1, variant="primary")

    # --- Event Handlers ---
    upload_btn.click(process_uploaded_files, inputs=[file_input], outputs=[upload_status])
    
    msg.submit(run_rag_chat, [msg, chatbot, lang_dropdown], [msg, chatbot, ref_output])
    submit_btn.click(run_rag_chat, [msg, chatbot, lang_dropdown], [msg, chatbot, ref_output])
    
    audio_input.stop_recording(voice_to_text_chat, [audio_input, chatbot, lang_dropdown], [msg, chatbot, ref_output])

if __name__ == "__main__":
    demo.launch(share=True)
